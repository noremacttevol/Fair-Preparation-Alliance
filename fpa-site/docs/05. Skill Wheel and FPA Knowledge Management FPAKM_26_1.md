2. **Over-Reliance on AI Predictions:** There’s a risk that members or leaders might put too much stock in the AI-generated survivability scores or recommendations, treating them as gospel. If the AI is wrong or if it fails to consider a factor, this could mislead preparation efforts. Conversely, a pessimistic AI assessment might demoralize someone unduly. **Mitigations:** We will constantly remind users that the AI is a **decision support tool, not a decision maker**. All AI-provided scores will come with caveats that they are estimates. We will encourage common-sense and personal judgment to override the AI when members have extra information. For example, if the AI says “you’re fine,” but the member knows they have a medical condition or personal circumstance the AI didn’t account for, they should trust themselves and even input that info into the system for better analysis. We’ll refine the AI continuously with real-world feedback (machine learning models will be retrained as we get more outcome data). And importantly, we will never frame the survivability score as a guarantee. It’s always “likelihood” or “projection.” All messaging around it will reinforce that it’s an aid to highlight strengths and weaknesses, not a crystal ball.