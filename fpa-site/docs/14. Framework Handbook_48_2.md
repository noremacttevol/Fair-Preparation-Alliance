All these AI functions are built to work without internet. The model and knowledge are stored on the device (or a squad’s field laptop). This was part of the Mk1Mod3 upgrade: Mk1Mod2 had some apps, but none of this AI capability.  
**Limitation Management:** We’re careful with AI. It’s not infallible. It might not know certain ultra-specific local details that a human would, and it might occasionally get something wrong (AI “hallucinations” as they call them). FPA’s approach is to treat the AI as a helpful advisor, but **not an authority**. The Trust Doctrine (Chapter 3) encourages verifying critical advice. For example, if the AI gives a medical recommendation that seems odd, members are taught to cross-check with the printed SHTF Bible or other resources if time allows. For high-stakes decisions, human judgment reigns – AI is a support tool.  
To minimize bad info, we keep the AI’s knowledge domain focused: essentially it knows the contents of our SHTF Bible, our SOPs, and standard reference books. It’s not freely browsing the internet (especially not in a crisis when there is none). This focus helps it stay accurate and on-mission. Also, we continuously train it on after-action reports, so it learns from real experiences (e.g., if a certain improvised technique worked well in the field, that might become part of its advice next time).