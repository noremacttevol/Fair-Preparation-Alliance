- **Moderation & Firewall:** The AI also performs **AI moderation** by monitoring communications and content for anything that violates our community standards or could be dangerous misinformation. It flags issues to human moderators or the Tribunal if necessary. On the flip side, an **AI Firewall** is in place to **restrain the AI’s outputs** – it prevents the AI from giving advice outside of approved topics (for example, it will refuse to give medical advice beyond what’s in our guide, instead directing the user to a human expert or official source). It also filters any external data it might use, insulating FPA from outside misinformation or malicious data. Essentially, the AI operates within strict guardrails: it’s a tool under our control, not an autonomous authority.  
- **Reliability Measures:** The AI system is built with redundancy and oversight. Critical AI functions (like the plan simulator) can run on multiple platforms – e.g., a lightweight on-device model for offline use and a more powerful cloud model for complex analysis when online – to ensure availability. All AI suggestions or actions above a certain risk threshold are logged and sometimes double-checked by a human (either a squad leader or an expert team). The AI’s knowledge is updated carefully via a controlled process (new training data must be approved and tested, aligning with the Trust Doctrine).