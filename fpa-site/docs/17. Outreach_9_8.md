On January 13, 2018, residents of Hawaii received a terrifying emergency alert on their phones: “**BALLISTIC MISSILE THREAT INBOUND... THIS IS NOT A DRILL**.” For 38 minutes, until a correction was issued, people believed they might be about to die in a nuclear attack. The alert was false – a result of human error during a drill – but the incident showcased critical outreach failures. **Firstly**, the interface and protocol of the alert system were flawed, allowing a single click to broadcast a live alert meant to be a test ([What the Erroneous Hawaiian Missile Alert Can Teach Us About ...](https://www.nngroup.com/articles/error-prevention/#:~:text=,it%20had%20been%20meant%20for)). **Secondly**, once the mistake was realized, there was no quick mechanism to retract or clarify the message via the same channel. It took over half an hour to issue a mobile correction, and in that time panic spread. Some people didn’t know what to do because preparedness outreach for such an event was minimal (few had guidance on sheltering from missiles). **Lesson learned:** A centralized alert system without proper safeguards or rapid correction capabilities can wreak havoc. Also, the public must be educated on emergency procedures _before_ an alert, or else the alert causes chaos rather than directed action. **FPA’s measures:** While missile warnings are (hopefully) rare, the principles apply broadly: we design our alerting and messaging processes to avoid single points of failure.