decisions coming out of those are being audited by people. If it proves useful and safe, we’ll expand it per member consensus. If it ever starts to undermine trust or ethics, it’s gone. We will not hand our alliance over to an algorithm. But we also don’t want to be Luddites if tech can genuinely boost our effectiveness. The Mk1Mod3 plan anticipates AI tools being part of our future **offline-first system** (with local AI instances that don’t depend on cloud connectivity), but again, always under human command. All of this is in line with our **[[AI Reliability & Human Oversight]]** protocols: no critical action or governance decision is executed without a human green-lighting it, and no AI will ever have decision rights within FPA. We use AI to augment our collective intelligence, never to replace human judgement.