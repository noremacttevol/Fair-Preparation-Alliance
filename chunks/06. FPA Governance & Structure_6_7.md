- **AI Oversight Structure (Pilot Program):** The FPA is cautiously leveraging artificial intelligence to assist with data analysis, predictions, and even governance suggestions – but we’re doing it with **strict oversight**. We have an **AI Oversight Committee** (members with tech and ethics expertise) that evaluates and monitors any AI tools we use. In other words, we’ve begun building an “AI oversight structure.” For example, we might use an AI to scan social media and weather data for early signs of a disaster, or to optimize logistics in a big relief operation. However, **AI does not get to make decisions on its own** in our governance. It can recommend, flag patterns, or offer a range of options, but human members always review and decide. We’re blunt about this: an AI is a tool, not a leader. Our structure defines who is responsible for any AI-generated output – there’s always a human in the loop, often two (tying back to our dual-auth rule for major calls). The Oversight Committee’s job is also to ensure the AI reflects our values (no biased suggestions that, say, favor one group over another in aid distribution) and to guard against over-reliance. We tag this as a **pilot effort**; as of now (experimental phase), only a few circles are using AI-driven dashboards and _all_ decisions coming out of those are being audited by people. If it proves useful and safe, we’ll expand it per member consensus. If it ever starts to undermine trust or ethics, it’s gone. We will not