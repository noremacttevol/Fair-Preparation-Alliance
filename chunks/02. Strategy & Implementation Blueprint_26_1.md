- Certain high-impact actions require human confirmation. For example, if the AI somehow were used to dispatch an alert to all members (maybe it detected a pattern that suggests a global threat), the firewall would hold that action until a human (with proper authority, e.g., a Tribunal tech member) approves it. The AI cannot “go rogue” and spam or panic everyone.  
- The firewall logs everything it blocks. If an AI response was stopped or flagged, that event goes to the transparency log (with as much detail as appropriate). This allows auditing of the AI’s attempted actions and helps improve its rules over time (and also alerts us if the AI was generating something unexpected).  
- **AI Moderation Team:** In addition to automated controls, we have an **AI oversight team** (could be a sub-committee under the Tribunal or a dedicated role for some tech-savvy members). They regularly review logs of AI behavior, investigate any anomalies, and adjust the firewall rules or AI training as needed. They also handle member feedback about the AI (“It gave a weird answer here” or “It flagged my innocent message as harmful”) and use that to fine-tune the system. Their job is to ensure the AI remains a positive force and that any negative impacts are caught early and corrected.