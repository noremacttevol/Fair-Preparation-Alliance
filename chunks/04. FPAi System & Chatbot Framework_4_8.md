- **Decision Support, _Not_ Decision Maker:** A key philosophy behind FPAi is that it is a **decision support tool** for members and leaders, _not_ an autocratic decision maker. Final calls always rest with humans. For instance, FPAi might analyze damage reports after a disaster to prioritize response, but the regional coordinator (a human) will make the final call on dispatching aid. In training scenarios, FPAi can suggest what drill to run next based on data, but squad leaders choose whether to follow that suggestion. This approach is very much like how modern emergency management agencies use AI – as an assistant that can process data and offer insights, while human judgment remains in charge ([FPA_All_Content_2024_dedup.md](file://xn--file-8chavoigzfxzbru5bsau7m%23:~:text=%20just%20as%20in%20modern,disaster%20risk%20and%20health%20management-o5415i/)). By clearly delineating AI’s role, FPA ensures we use these advanced tools in a balanced way. The AI is **constrained** to operate within its sphere: it won’t, for example, try to override a human command or venture into leadership decisions. It also adheres strictly to FPA’s protocols. If a member asks something that falls outside FPA’s approved scope or ethics, FPAi is programmed to refuse or refer the query to a human. This keeps the AI “in its lane” as a helpful assistant.