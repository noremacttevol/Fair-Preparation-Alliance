name: AI Documentation Fixer + Term Audit

on:
  push:
    branches: [main]
  workflow_dispatch:

concurrency:
  group: ai-doc-fix-${{ github.ref }}
  cancel-in-progress: true

jobs:
  auto_fix_docs:
    if: ${{ !contains(github.event.head_commit.message, '[AI fix]') }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      # 1.  Check out repo
      - uses: actions/checkout@v3
        with: { fetch-depth: 2 }

      # 2.  Python
      - uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      # 3.  Deps
      - name: Install deps
        run: pip install --no-cache-dir openai tiktoken

      # 4.  Existing linter
      - name: Run AI doc fixer
        env: { OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }} }
        run: python .github/scripts/ai_doc_fix.py

      # 5.  üîç Term-audit (self-contained)
      - name: Run term audit
        env: { OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }} }
        run: |
          python - <<'PY'
          import os, re, json, pathlib, collections, subprocess, sys
          ROOT = pathlib.Path('.').resolve()
          DICT = ROOT / "00_Core" / "13. Dictionary (Q&A + Links).md"
          openai_key = os.getenv("OPENAI_API_KEY")

          # Load known terms
          known = set()
          if DICT.exists():
              for line in DICT.read_text(encoding='utf8').splitlines():
                  if '‚Äî' in line:
                      known.add(line.split('‚Äî')[0].strip())

          # Collect unknown [[WikiLinks]]
          wiki = re.compile(r'\[\[([^\]]+?)\]\]')
          hits = collections.Counter()
          for md in ROOT.rglob('*.md'):
              if '99_Archive' in md.parts or md == DICT: continue
              for term in wiki.findall(md.read_text(errors='ignore')):
                  term = term.strip()
                  if term and term not in known:
                      hits[term] += 1
          if not hits:
              print("‚úì No new terms"); sys.exit(0)

          # Ask GPT
          import openai; openai.api_key = openai_key
          prompt = (
            "For each TERM decide KEEP / MAP / DROP. "
            "If KEEP: give a 1-line definition. "
            "If MAP: give canonical term from list. "
            "Return JSON list."
          )
          prompt += "\nKNOWN: " + ', '.join(list(known)[:2000])
          prompt += "\nTERMS: " + ', '.join(hits)
          resp = openai.ChatCompletion.create(
              model="gpt-4o-mini",
              messages=[{"role":"system","content":prompt}],
              temperature=0
          ).choices[0].message.content.strip()
          try:
              decisions = json.loads(resp)
          except json.JSONDecodeError:
              print("‚úó GPT bad JSON"); sys.exit(1)

          # Apply decisions
          edits = False
          DICT.parent.mkdir(parents=True, exist_ok=True)
          with DICT.open('a', encoding='utf8') as dfile:
              for row in decisions:
                  act = row['action'].upper(); term = row['term']
                  if act == 'KEEP':
                      dfile.write(f"{term} ‚Äî {row.get('definition','TBD')}  |  avoid: n/a\n")
                      edits = True
                  elif act == 'MAP':
                      canon = row.get('canonical') or row.get('definition') or term
                      for md in ROOT.rglob('*.md'):
                          if '99_Archive' in md.parts or md == DICT: continue
                          txt = md.read_text(encoding='utf8')
                          new = txt.replace(f'[[{term}]]', f'[[{canon}]]')
                          if new != txt:
                              md.write_text(new, encoding='utf8'); edits = True
                  # DROP ‚Üí do nothing (linter will flag)

          if edits:
              subprocess.run('git config user.name  "vault-bot"', shell=True)
              subprocess.run('git config user.email "actions@github"', shell=True)
              subprocess.run('git add .', shell=True)
              subprocess.run('git commit -m "[AI fix] term audit"', shell=True)
          PY
