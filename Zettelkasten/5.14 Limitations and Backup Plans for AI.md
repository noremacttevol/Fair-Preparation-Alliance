## 5.14 Limitations and Backup Plans for AI

FPA remains clear-eyed about the limitations of AI, treating it as a helpful tool but not a crutch. First, AI systems require power and often computing resources – in a long-term grid-down (Phase 3), running complex AI might be unsustainable, so the alliance sets priorities: which AI functions are mission-critical to try to keep alive via generators or solar (perhaps the communication assistant or knowledge query) and which can be let go (maybe the high-end simulation forecasts). They also understand AI is only as good as its data; if a disaster scenario is very different from what the AI was trained on, its advice could be off-base. Therefore, any AI recommendation that seems unusual is cross-checked by experienced members. The group has also war-gamed scenarios where AI is outright unavailable or gives faulty outputs. For example, if their logistics AI fails, they revert to manual inventory counts and human intuition for supply distribution – hence, those fundamental skills are still taught. There’s caution about over-reliance: a conscious practice might be occasionally doing tasks without AI to ensure they remember how (like navigating with paper maps instead of GPS, or calculating water needs with pencil and paper). Moreover, in the event of device damage (say an EMP or cyber-attack knocks out their computers), FPA has a digital recovery plan: important AI software and data are backed up on hardened storage, and instructions exist to rebuild critical systems from scratch if needed. In short, the Alliance plans for AI to fail just as it plans for infrastructure to fail. By acknowledging these limitations, they maintain technological resilience – grateful for AI’s help when available, but perfectly capable of carrying on without it. This balanced approach ensures that AI remains a servant to their mission, never the master of it.